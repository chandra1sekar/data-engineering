<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Week 13 - sync session">
  <title>Fundamentals of Data Engineering</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/mids.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
  <h1 class="title">Fundamentals of Data Engineering</h1>
  <h2 class="author">Week 13 - sync session</h2>
  <img class="frontPageSlogan" src="http://people.ischool.berkeley.edu/~mark.mims/course-development/2017-mids-w205/media/datascience-at-berkeley.png"/>
</section>

<section id="section" class="slide level1">
<h1></h1>
<section id="get-started" class="level2">
<h2>Get Started</h2>
<pre><code>git pull in ~/w205/course-content
mkdir ~/w205/full-stack2/
cd ~/w205/full-stack2
cp ~/w205/course-content/13-Understanding-Data/docker-compose.yml .
docker-compose pull
cp ~/w205/course-content/13-Understanding-Data/*.py .
</code></pre>
<aside class="notes">

</aside>
</section>
</section>
<section id="section-1" class="slide level1">
<h1></h1>
<section id="section-2" class="level2" data-background="images/pipeline-steel-thread-for-mobile-app.svg">
<h2></h2>
<aside class="notes">
<p>Let’s walk through this - user interacts with mobile app - mobile app makes API calls to web services - API server handles requests: - handles actual business requirements (e.g., process purchase) - logs events to kafka - spark then: - pulls events from kafka - filters/flattens/transforms events - writes them to storage - presto then queries those events</p>
</aside>
</section>
</section>
<section id="section-3" class="slide level1">
<h1></h1>
<section id="flask-kafka-spark-hadoop-presto-part-ii" class="level2">
<h2>Flask-Kafka-Spark-Hadoop-Presto Part II</h2>
<aside class="notes">
<ul>
<li>last week we did spark from files</li>
<li>ended with spark files reading from kafka, did some munging events, extracted events, json explode, did some filtering for event types.</li>
</ul>
</aside>
</section>
</section>
<section id="section-4" class="slide level1">
<h1></h1>
<section id="setup" class="level2">
<h2>Setup</h2>
</section>
<section id="the-docker-compose.yml" class="level2">
<h2>The <code>docker-compose.yml</code></h2>
<p>Create a <code>docker-compose.yml</code> with the following</p>
<pre><code>---
version: &#39;2&#39;
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
    expose:
      - &quot;2181&quot;
      - &quot;2888&quot;
      - &quot;32181&quot;
      - &quot;3888&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    expose:
      - &quot;9092&quot;
      - &quot;29092&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  cloudera:
    image: midsw205/hadoop:0.0.2
    hostname: cloudera
    expose:
      - &quot;8020&quot; # nn
      - &quot;8888&quot; # hue
      - &quot;9083&quot; # hive thrift
      - &quot;10000&quot; # hive jdbc
      - &quot;50070&quot; # nn http
    ports:
      - &quot;8888:8888&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  spark:
    image: midsw205/spark-python:0.0.6
    stdin_open: true
    tty: true
    volumes:
      - ~/w205:/w205
    expose:
      - &quot;8888&quot;
    #ports:
    #  - &quot;8888:8888&quot;
    depends_on:
      - cloudera
    environment:
      HADOOP_NAMENODE: cloudera
      HIVE_THRIFTSERVER: cloudera:9083
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;
    command: bash

  presto:
    image: midsw205/presto:0.0.1
    hostname: presto
    volumes:
      - ~/w205:/w205
    expose:
      - &quot;8080&quot;
    environment:
      HIVE_THRIFTSERVER: cloudera:9083
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;

  mids:
    image: midsw205/base:0.1.9
    stdin_open: true
    tty: true
    volumes:
      - ~/w205:/w205
    expose:
      - &quot;5000&quot;
    ports:
      - &quot;5000:5000&quot;
    extra_hosts:
      - &quot;moby:127.0.0.1&quot;</code></pre>
<aside class="notes">
<p>k, z same - cloudera a little thinner, a few extra environment variables - presto new conainer</p>
</aside>
</section>
<section id="spin-up-the-cluster" class="level2">
<h2>Spin up the cluster</h2>
<pre><code>docker-compose up -d</code></pre>
<aside class="notes">
<ul>
<li>Now spin up the cluster</li>
</ul>
<pre><code>docker-compose up -d</code></pre>
<ul>
<li>Notice we didn’t actually create a topic as the broker does this for you</li>
</ul>
</aside>
</section>
<section id="web-app" class="level2">
<h2>Web-app</h2>
<ul>
<li>Take our instrumented web-app from before <code>~/w205/full-stack/game_api.py</code></li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="im">from</span> kafka <span class="im">import</span> KafkaProducer</a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="im">from</span> flask <span class="im">import</span> Flask, request</a>
<a class="sourceLine" id="cb5-5" data-line-number="5"></a>
<a class="sourceLine" id="cb5-6" data-line-number="6">app <span class="op">=</span> Flask(<span class="va">__name__</span>)</a>
<a class="sourceLine" id="cb5-7" data-line-number="7">producer <span class="op">=</span> KafkaProducer(bootstrap_servers<span class="op">=</span><span class="st">&#39;kafka:29092&#39;</span>)</a>
<a class="sourceLine" id="cb5-8" data-line-number="8"></a>
<a class="sourceLine" id="cb5-9" data-line-number="9"></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="kw">def</span> log_to_kafka(topic, event):</a>
<a class="sourceLine" id="cb5-11" data-line-number="11">    event.update(request.headers)</a>
<a class="sourceLine" id="cb5-12" data-line-number="12">    producer.send(topic, json.dumps(event).encode())</a>
<a class="sourceLine" id="cb5-13" data-line-number="13"></a>
<a class="sourceLine" id="cb5-14" data-line-number="14"></a>
<a class="sourceLine" id="cb5-15" data-line-number="15"><span class="at">@app.route</span>(<span class="st">&quot;/&quot;</span>)</a>
<a class="sourceLine" id="cb5-16" data-line-number="16"><span class="kw">def</span> default_response():</a>
<a class="sourceLine" id="cb5-17" data-line-number="17">    default_event <span class="op">=</span> {<span class="st">&#39;event_type&#39;</span>: <span class="st">&#39;default&#39;</span>}</a>
<a class="sourceLine" id="cb5-18" data-line-number="18">    log_to_kafka(<span class="st">&#39;events&#39;</span>, default_event)</a>
<a class="sourceLine" id="cb5-19" data-line-number="19">    <span class="cf">return</span> <span class="st">&quot;This is the default response!</span><span class="ch">\n</span><span class="st">&quot;</span></a>
<a class="sourceLine" id="cb5-20" data-line-number="20"></a>
<a class="sourceLine" id="cb5-21" data-line-number="21"></a>
<a class="sourceLine" id="cb5-22" data-line-number="22"><span class="at">@app.route</span>(<span class="st">&quot;/purchase_a_sword&quot;</span>)</a>
<a class="sourceLine" id="cb5-23" data-line-number="23"><span class="kw">def</span> purchase_a_sword():</a>
<a class="sourceLine" id="cb5-24" data-line-number="24">    purchase_sword_event <span class="op">=</span> {<span class="st">&#39;event_type&#39;</span>: <span class="st">&#39;purchase_sword&#39;</span>}</a>
<a class="sourceLine" id="cb5-25" data-line-number="25">    log_to_kafka(<span class="st">&#39;events&#39;</span>, purchase_sword_event)</a>
<a class="sourceLine" id="cb5-26" data-line-number="26">    <span class="cf">return</span> <span class="st">&quot;Sword Purchased!</span><span class="ch">\n</span><span class="st">&quot;</span></a></code></pre></div>
<aside class="notes">
<ul>
<li>same web app as before</li>
</ul>
</aside>
</section>
<section id="run-flask" class="level2">
<h2>run flask</h2>
<pre><code>docker-compose exec mids \
  env FLASK_APP=/w205/full-stack/game_api.py \
  flask run --host 0.0.0.0</code></pre>
<aside class="notes">
<pre><code>docker-compose exec mids env FLASK_APP=/w205/full-stack/game_api.py flask run --host 0.0.0.0</code></pre>
</aside>
</section>
<section id="set-up-to-watch-kafka" class="level2">
<h2>Set up to watch kafka</h2>
<pre><code>docker-compose exec mids \
  kafkacat -C -b kafka:29092 -t events -o beginning</code></pre>
<aside class="notes">
<ul>
<li>new terminal window, leave up</li>
<li>running kafkacat without -e so it will run continuously</li>
</ul>
<pre><code>docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning</code></pre>
</aside>
</section>
<section id="apache-bench-to-generate-data" class="level2">
<h2>Apache Bench to generate data</h2>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<aside class="notes">
<ul>
<li>Will do lots more events with streaming later in class.</li>
</ul>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
</aside>
</section>
</section>
<section id="section-5" class="slide level1">
<h1></h1>
<section id="some-spark-to-write-events" class="level2">
<h2>Some Spark to Write Events</h2>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb18-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb18-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb18-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession, Row</a>
<a class="sourceLine" id="cb18-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf</a>
<a class="sourceLine" id="cb18-7" data-line-number="7"></a>
<a class="sourceLine" id="cb18-8" data-line-number="8"></a>
<a class="sourceLine" id="cb18-9" data-line-number="9"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb18-10" data-line-number="10"><span class="kw">def</span> is_purchase(event_as_json):</a>
<a class="sourceLine" id="cb18-11" data-line-number="11">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb18-12" data-line-number="12">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb18-13" data-line-number="13">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb18-14" data-line-number="14">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb18-15" data-line-number="15"></a>
<a class="sourceLine" id="cb18-16" data-line-number="16"></a>
<a class="sourceLine" id="cb18-17" data-line-number="17"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb18-18" data-line-number="18">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb18-19" data-line-number="19"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb18-20" data-line-number="20">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb18-21" data-line-number="21">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb18-22" data-line-number="22">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-23" data-line-number="23">        .getOrCreate()</a>
<a class="sourceLine" id="cb18-24" data-line-number="24"></a>
<a class="sourceLine" id="cb18-25" data-line-number="25">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb18-26" data-line-number="26">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb18-27" data-line-number="27">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-28" data-line-number="28">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-29" data-line-number="29">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-30" data-line-number="30">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-31" data-line-number="31">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-32" data-line-number="32">        .load()</a>
<a class="sourceLine" id="cb18-33" data-line-number="33"></a>
<a class="sourceLine" id="cb18-34" data-line-number="34">    purchase_events <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb18-35" data-line-number="35">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw&#39;</span>),</a>
<a class="sourceLine" id="cb18-36" data-line-number="36">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-37" data-line-number="37">        .<span class="bu">filter</span>(is_purchase(<span class="st">&#39;raw&#39;</span>))</a>
<a class="sourceLine" id="cb18-38" data-line-number="38"></a>
<a class="sourceLine" id="cb18-39" data-line-number="39">    extracted_purchase_events <span class="op">=</span> purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb18-40" data-line-number="40">        .rdd <span class="op">\</span></a>
<a class="sourceLine" id="cb18-41" data-line-number="41">        .<span class="bu">map</span>(<span class="kw">lambda</span> r: Row(timestamp<span class="op">=</span>r.timestamp, <span class="op">**</span>json.loads(r.raw))) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-42" data-line-number="42">        .toDF()</a>
<a class="sourceLine" id="cb18-43" data-line-number="43">    extracted_purchase_events.printSchema()</a>
<a class="sourceLine" id="cb18-44" data-line-number="44">    extracted_purchase_events.show()</a>
<a class="sourceLine" id="cb18-45" data-line-number="45"></a>
<a class="sourceLine" id="cb18-46" data-line-number="46">    extracted_purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb18-47" data-line-number="47">        .write <span class="op">\</span></a>
<a class="sourceLine" id="cb18-48" data-line-number="48">        .mode(<span class="st">&#39;overwrite&#39;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb18-49" data-line-number="49">        .parquet(<span class="st">&#39;/tmp/purchases&#39;</span>)</a>
<a class="sourceLine" id="cb18-50" data-line-number="50"></a>
<a class="sourceLine" id="cb18-51" data-line-number="51"></a>
<a class="sourceLine" id="cb18-52" data-line-number="52"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb18-53" data-line-number="53">    main()</a></code></pre></div>
<aside class="notes">
<ul>
<li>Reminder of pieces and parts</li>
<li>Filtering on is_purchase</li>
<li>Write to tmp/purchases in hdfs</li>
</ul>
</aside>
</section>
<section id="run-this" class="level2">
<h2>Run this</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/filtered_writes.py</code></pre>
</section>
<section id="see-purchases-in-hdfs" class="level2">
<h2>See purchases in hdfs</h2>
<pre><code>docker-compose exec cloudera hadoop fs -ls /tmp/purchases/</code></pre>
</section>
</section>
<section id="section-6" class="slide level1">
<h1></h1>
<section id="queries-from-presto" class="level2">
<h2>Queries from Presto</h2>
</section>
<section id="hive-metastore" class="level2">
<h2>Hive metastore</h2>
<ul>
<li>Track schema</li>
<li>Create a table</li>
</ul>
<aside class="notes">
<ul>
<li><p>The Hive metastore is a really common tool used to keep track of schema for tables used throughout the Hadoop and Spark ecosystem (schema registry).</p></li>
<li><p>To “expose” the schema for our “purchases”… we need to create a table in the hive metastore.</p></li>
<li>In hadoop ecosystem,</li>
<li>hive is a full on query engine, we don’t use it any longer b/c it’s slow, but we use the schema registry</li>
<li>The hive metastore is friendly with multiple partitions being stored on the fs, everything that talks to hadoop can talk to the hive metastore.</li>
<li>We write it with spark and we want to read it with presto, to get them to agree we track the schema with hive metastore</li>
<li>Hive server you usually interface with the thrift server (a seriazation critter) but it’s actually set up as a relational db, mysql or postgresql, tracking these table names have these fields etc</li>
<li><p>We have a hive metastore spun up in our cloudera container(that’s why we needed a new cloudera container)</p></li>
<li>There are two ways
<ul>
<li>Run hive explicitly and create an external table</li>
<li>Run spark, create a</li>
</ul></li>
</ul>
</aside>
</section>
<section id="hard-way" class="level2">
<h2>Hard Way</h2>
<pre><code>docker-compose exec cloudera hive</code></pre>
<aside class="notes">
<ul>
<li>Run hive in the hadoop container using the hive command line</li>
<li>This is what you would do, don’t need to actually do it, skip to easier way</li>
<li>This is deprecated at this point</li>
</ul>
</aside>
</section>
<section id="section-7" class="level2">
<h2></h2>
<div class="sourceCode" id="cb22"><pre class="sourceCode sql"><code class="sourceCode sql"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="kw">create</span> external <span class="kw">table</span> <span class="kw">if</span> <span class="kw">not</span> <span class="kw">exists</span> default.purchases2 (</a>
<a class="sourceLine" id="cb22-2" data-line-number="2">    Accept string,</a>
<a class="sourceLine" id="cb22-3" data-line-number="3">    Host string,</a>
<a class="sourceLine" id="cb22-4" data-line-number="4">    User_Agent string,</a>
<a class="sourceLine" id="cb22-5" data-line-number="5">    event_type string,</a>
<a class="sourceLine" id="cb22-6" data-line-number="6">    <span class="dt">timestamp</span> string</a>
<a class="sourceLine" id="cb22-7" data-line-number="7">  )</a>
<a class="sourceLine" id="cb22-8" data-line-number="8">  stored <span class="kw">as</span> parquet </a>
<a class="sourceLine" id="cb22-9" data-line-number="9">  location <span class="st">&#39;/tmp/purchases&#39;</span></a>
<a class="sourceLine" id="cb22-10" data-line-number="10">  tblproperties (<span class="ot">&quot;parquet.compress&quot;</span>=<span class="ot">&quot;SNAPPY&quot;</span>);</a></code></pre></div>
<aside class="notes">
<pre><code>create external table if not exists default.purchases2 (Accept string, Host string, User_Agent string, event_type string, timestamp string) stored as parquet location &#39;/tmp/purchases&#39;  tblproperties (&quot;parquet.compress&quot;=&quot;SNAPPY&quot;);</code></pre>
</aside>
</section>
<section id="or-we-can-do-this-an-easier-way" class="level2">
<h2>Or… we can do this an easier way</h2>
<pre><code>docker-compose exec spark pyspark</code></pre>
<aside class="notes">
<ul>
<li>run spark</li>
<li>what we want to do is run another spark job to start up pyspark, could do spark nb etc</li>
</ul>
</aside>
</section>
<section id="section-8" class="level2">
<h2></h2>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb25-1" data-line-number="1">df <span class="op">=</span> spark.read.parquet(<span class="st">&#39;/tmp/purchases&#39;</span>)</a>
<a class="sourceLine" id="cb25-2" data-line-number="2">df.registerTempTable(<span class="st">&#39;purchases&#39;</span>)</a>
<a class="sourceLine" id="cb25-3" data-line-number="3">query <span class="op">=</span> <span class="st">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb25-4" data-line-number="4"><span class="st">create external table purchase_events</span></a>
<a class="sourceLine" id="cb25-5" data-line-number="5"><span class="st">  stored as parquet</span></a>
<a class="sourceLine" id="cb25-6" data-line-number="6"><span class="st">  location &#39;/tmp/purchase_events&#39;</span></a>
<a class="sourceLine" id="cb25-7" data-line-number="7"><span class="st">  as</span></a>
<a class="sourceLine" id="cb25-8" data-line-number="8"><span class="st">  select * from purchases</span></a>
<a class="sourceLine" id="cb25-9" data-line-number="9"><span class="st">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb25-10" data-line-number="10">spark.sql(query)</a></code></pre></div>
<aside class="notes">
<pre><code>spark.sql(&quot;create external table purchase_events stored as parquet location &#39;/tmp/purchase_events&#39; as select * from purchases&quot;)</code></pre>
<ul>
<li>read parquet from what we wrote into hdfs</li>
<li>register temp table</li>
<li>create external table purchase event</li>
<li>store as parquet</li>
<li>similar to what we saw in hard example</li>
<li>we’re still going to cheat and implicitly infer schema - but just getting it by select * from another df</li>
</ul>
</aside>
</section>
<section id="can-just-include-all-that-in-job" class="level2">
<h2>Can just include all that in job</h2>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb27-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb27-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb27-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession, Row</a>
<a class="sourceLine" id="cb27-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf</a>
<a class="sourceLine" id="cb27-7" data-line-number="7"></a>
<a class="sourceLine" id="cb27-8" data-line-number="8"></a>
<a class="sourceLine" id="cb27-9" data-line-number="9"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb27-10" data-line-number="10"><span class="kw">def</span> is_purchase(event_as_json):</a>
<a class="sourceLine" id="cb27-11" data-line-number="11">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb27-12" data-line-number="12">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb27-13" data-line-number="13">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb27-14" data-line-number="14">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb27-15" data-line-number="15"></a>
<a class="sourceLine" id="cb27-16" data-line-number="16"></a>
<a class="sourceLine" id="cb27-17" data-line-number="17"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb27-18" data-line-number="18">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb27-19" data-line-number="19"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb27-20" data-line-number="20">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb27-21" data-line-number="21">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb27-22" data-line-number="22">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb27-23" data-line-number="23">        .enableHiveSupport() <span class="op">\</span></a>
<a class="sourceLine" id="cb27-24" data-line-number="24">        .getOrCreate()</a>
<a class="sourceLine" id="cb27-25" data-line-number="25"></a>
<a class="sourceLine" id="cb27-26" data-line-number="26">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb27-27" data-line-number="27">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb27-28" data-line-number="28">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb27-29" data-line-number="29">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb27-30" data-line-number="30">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb27-31" data-line-number="31">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb27-32" data-line-number="32">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb27-33" data-line-number="33">        .load()</a>
<a class="sourceLine" id="cb27-34" data-line-number="34"></a>
<a class="sourceLine" id="cb27-35" data-line-number="35">    purchase_events <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb27-36" data-line-number="36">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw&#39;</span>),</a>
<a class="sourceLine" id="cb27-37" data-line-number="37">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb27-38" data-line-number="38">        .<span class="bu">filter</span>(is_purchase(<span class="st">&#39;raw&#39;</span>))</a>
<a class="sourceLine" id="cb27-39" data-line-number="39"></a>
<a class="sourceLine" id="cb27-40" data-line-number="40">    extracted_purchase_events <span class="op">=</span> purchase_events <span class="op">\</span></a>
<a class="sourceLine" id="cb27-41" data-line-number="41">        .rdd <span class="op">\</span></a>
<a class="sourceLine" id="cb27-42" data-line-number="42">        .<span class="bu">map</span>(<span class="kw">lambda</span> r: Row(timestamp<span class="op">=</span>r.timestamp, <span class="op">**</span>json.loads(r.raw))) <span class="op">\</span></a>
<a class="sourceLine" id="cb27-43" data-line-number="43">        .toDF()</a>
<a class="sourceLine" id="cb27-44" data-line-number="44">    extracted_purchase_events.printSchema()</a>
<a class="sourceLine" id="cb27-45" data-line-number="45">    extracted_purchase_events.show()</a>
<a class="sourceLine" id="cb27-46" data-line-number="46"></a>
<a class="sourceLine" id="cb27-47" data-line-number="47">    extracted_purchase_events.registerTempTable(<span class="st">&quot;extracted_purchase_events&quot;</span>)</a>
<a class="sourceLine" id="cb27-48" data-line-number="48"></a>
<a class="sourceLine" id="cb27-49" data-line-number="49">    spark.sql(<span class="st">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb27-50" data-line-number="50"><span class="st">        create external table purchases</span></a>
<a class="sourceLine" id="cb27-51" data-line-number="51"><span class="st">        stored as parquet</span></a>
<a class="sourceLine" id="cb27-52" data-line-number="52"><span class="st">        location &#39;/tmp/purchases&#39;</span></a>
<a class="sourceLine" id="cb27-53" data-line-number="53"><span class="st">        as</span></a>
<a class="sourceLine" id="cb27-54" data-line-number="54"><span class="st">        select * from extracted_purchase_events</span></a>
<a class="sourceLine" id="cb27-55" data-line-number="55"><span class="st">    &quot;&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb27-56" data-line-number="56"></a>
<a class="sourceLine" id="cb27-57" data-line-number="57"></a>
<a class="sourceLine" id="cb27-58" data-line-number="58"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb27-59" data-line-number="59">    main()</a></code></pre></div>
<aside class="notes">
<ul>
<li>Modified filtered_writes.py to register a temp table and then run it from w/in spark itself</li>
</ul>
</aside>
</section>
<section id="run-this-1" class="level2">
<h2>Run this</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/write_hive_table.py</code></pre>
</section>
<section id="see-it-wrote-to-hdfs" class="level2">
<h2>See it wrote to hdfs</h2>
<pre><code>docker-compose exec cloudera hadoop fs -ls /tmp/</code></pre>
<aside class="notes">
<ul>
<li>This is the first spark job to run - it does it all, read, flatten, write, ?query</li>
</ul>
</aside>
</section>
<section id="and-now" class="level2">
<h2>and now …</h2>
<ul>
<li>Query this with presto</li>
</ul>
<pre><code>docker-compose exec presto presto --server presto:8080 --catalog hive --schema default</code></pre>
<aside class="notes">
<ul>
<li>Presto just a query engine</li>
<li>it’s talking to the hive thrift server to get the table we just added</li>
<li>connected to hdfs to get the data</li>
<li>Querying with presto instead of spark bc presto scales well, handles a wider range of sql syntax, can start treating like a database, can configure it to talk to cassandra, s3 directly, kafka directly, mysql, good front end for your company’s data lake</li>
<li>We’re overloading the word presto here</li>
</ul>
</aside>
</section>
<section id="what-tables-do-we-have-in-presto" class="level2">
<h2>What tables do we have in Presto?</h2>
<pre><code>presto:default&gt; show tables;
   Table   
-----------
 purchases 
(1 row)

Query 20180404_224746_00009_zsma3, FINISHED, 1 node
Splits: 2 total, 1 done (50.00%)
0:00 [1 rows, 34B] [10 rows/s, 342B/s]</code></pre>
</section>
<section id="describe-purchases-table" class="level2">
<h2>Describe <code>purchases</code> table</h2>
<pre><code>presto:default&gt; describe purchases;
   Column   |  Type   | Comment 
------------+---------+---------
 accept     | varchar |         
 host       | varchar |         
 user-agent | varchar |         
 event_type | varchar |         
 timestamp  | varchar |         
(5 rows)

Query 20180404_224828_00010_zsma3, FINISHED, 1 node
Splits: 2 total, 1 done (50.00%)
0:00 [5 rows, 344B] [34 rows/s, 2.31KB/s]</code></pre>
</section>
<section id="query-purchases-table" class="level2">
<h2>Query <code>purchases</code> table</h2>
<pre><code>presto:default&gt; select * from purchases;
 accept |       host        |   user-agent    |   event_type   |        timestamp        
--------+-------------------+-----------------+----------------+-------------------------
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.124 
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.128 
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.131 
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.135 
 */*    | user1.comcast.com | ApacheBench/2.3 | purchase_sword | 2018-04-04 22:36:13.138
 ...</code></pre>
</section>
</section>
<section id="section-9" class="slide level1">
<h1></h1>
<section id="streaming" class="level2">
<h2>Streaming</h2>
<aside class="notes">
<ul>
<li>Back at the pipeline pic:</li>
<li>scale well: spark, kafka &amp; presto (linear up to 200 machines or so); hadoop (not great),<br />
</li>
<li>run same stack in different execution context - wouldn’t have to use fundamentally different tools (except flask really, I’d use go or something else)</li>
<li>write stateless applications</li>
<li>behind load balancers</li>
</ul>
</aside>
</section>
<section id="getting-our-spark-ready-for-streaming" class="level2">
<h2>Getting our spark ready for streaming</h2>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb34-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb34-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb34-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb34-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb34-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</a>
<a class="sourceLine" id="cb34-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf, from_json</a>
<a class="sourceLine" id="cb34-7" data-line-number="7"><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField, StringType</a>
<a class="sourceLine" id="cb34-8" data-line-number="8"></a>
<a class="sourceLine" id="cb34-9" data-line-number="9"></a>
<a class="sourceLine" id="cb34-10" data-line-number="10"><span class="kw">def</span> purchase_sword_event_schema():</a>
<a class="sourceLine" id="cb34-11" data-line-number="11">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb34-12" data-line-number="12"><span class="co">    root</span></a>
<a class="sourceLine" id="cb34-13" data-line-number="13"><span class="co">    |-- Accept: string (nullable = true)</span></a>
<a class="sourceLine" id="cb34-14" data-line-number="14"><span class="co">    |-- Host: string (nullable = true)</span></a>
<a class="sourceLine" id="cb34-15" data-line-number="15"><span class="co">    |-- User-Agent: string (nullable = true)</span></a>
<a class="sourceLine" id="cb34-16" data-line-number="16"><span class="co">    |-- event_type: string (nullable = true)</span></a>
<a class="sourceLine" id="cb34-17" data-line-number="17"><span class="co">    |-- timestamp: string (nullable = true)</span></a>
<a class="sourceLine" id="cb34-18" data-line-number="18"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb34-19" data-line-number="19">    <span class="cf">return</span> StructType([</a>
<a class="sourceLine" id="cb34-20" data-line-number="20">        StructField(<span class="st">&quot;Accept&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb34-21" data-line-number="21">        StructField(<span class="st">&quot;Host&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb34-22" data-line-number="22">        StructField(<span class="st">&quot;User-Agent&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb34-23" data-line-number="23">        StructField(<span class="st">&quot;event_type&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb34-24" data-line-number="24">    ])</a>
<a class="sourceLine" id="cb34-25" data-line-number="25"></a>
<a class="sourceLine" id="cb34-26" data-line-number="26"></a>
<a class="sourceLine" id="cb34-27" data-line-number="27"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb34-28" data-line-number="28"><span class="kw">def</span> is_sword_purchase(event_as_json):</a>
<a class="sourceLine" id="cb34-29" data-line-number="29">    <span class="co">&quot;&quot;&quot;udf for filtering events</span></a>
<a class="sourceLine" id="cb34-30" data-line-number="30"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb34-31" data-line-number="31">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb34-32" data-line-number="32">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb34-33" data-line-number="33">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb34-34" data-line-number="34">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb34-35" data-line-number="35"></a>
<a class="sourceLine" id="cb34-36" data-line-number="36"></a>
<a class="sourceLine" id="cb34-37" data-line-number="37"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb34-38" data-line-number="38">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb34-39" data-line-number="39"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb34-40" data-line-number="40">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb34-41" data-line-number="41">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb34-42" data-line-number="42">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb34-43" data-line-number="43">        .getOrCreate()</a>
<a class="sourceLine" id="cb34-44" data-line-number="44"></a>
<a class="sourceLine" id="cb34-45" data-line-number="45">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb34-46" data-line-number="46">        .read <span class="op">\</span></a>
<a class="sourceLine" id="cb34-47" data-line-number="47">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb34-48" data-line-number="48">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb34-49" data-line-number="49">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb34-50" data-line-number="50">        .option(<span class="st">&quot;startingOffsets&quot;</span>, <span class="st">&quot;earliest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb34-51" data-line-number="51">        .option(<span class="st">&quot;endingOffsets&quot;</span>, <span class="st">&quot;latest&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb34-52" data-line-number="52">        .load()</a>
<a class="sourceLine" id="cb34-53" data-line-number="53"></a>
<a class="sourceLine" id="cb34-54" data-line-number="54">    sword_purchases <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb34-55" data-line-number="55">        .<span class="bu">filter</span>(is_sword_purchase(raw_events.value.cast(<span class="st">&#39;string&#39;</span>))) <span class="op">\</span></a>
<a class="sourceLine" id="cb34-56" data-line-number="56">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw_event&#39;</span>),</a>
<a class="sourceLine" id="cb34-57" data-line-number="57">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb34-58" data-line-number="58">                from_json(raw_events.value.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb34-59" data-line-number="59">                          purchase_sword_event_schema()).alias(<span class="st">&#39;json&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb34-60" data-line-number="60">        .select(<span class="st">&#39;raw_event&#39;</span>, <span class="st">&#39;timestamp&#39;</span>, <span class="st">&#39;json.*&#39;</span>)</a>
<a class="sourceLine" id="cb34-61" data-line-number="61"></a>
<a class="sourceLine" id="cb34-62" data-line-number="62">    sword_purchases.printSchema()</a>
<a class="sourceLine" id="cb34-63" data-line-number="63">    sword_purchases.show(<span class="dv">100</span>)</a>
<a class="sourceLine" id="cb34-64" data-line-number="64"></a>
<a class="sourceLine" id="cb34-65" data-line-number="65"></a>
<a class="sourceLine" id="cb34-66" data-line-number="66"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb34-67" data-line-number="67">    main()</a></code></pre></div>
<aside class="notes">
<ul>
<li>specify purchase_sword_event_schema schema in the job (before were inferring schema - doing that in the ‘.rdd  .map(etc)  .toDF()’ this is fine but fairly brittle. In a production pipeline you want to explictly specify the schema.)</li>
<li>rename is_purchase so specific to swords</li>
<li>Combining a bunch of steps from before</li>
<li>Not going to the rdd</li>
<li>Start with raw events, filter whether they’re sword purchases,</li>
<li>Doing a lot (both the select and the filter we did in 2 steps before) in that one step for filtering sword purchases</li>
<li>will have a column in the output of keep the raw event, can always go back and reexamine</li>
<li>The from json has two pieces - the actual column and the schema</li>
<li>select 3 columns: value, timestamp, the json created</li>
<li>Best practices</li>
<li>Robust against different schema, but that can be a gotcha if you end up with data that isn’t formatted how you thought it was</li>
<li>Streaming datasets don’t allow you to access the rdd as we did before</li>
<li>This isn’t writing the hive table for us</li>
</ul>
</aside>
</section>
<section id="run" class="level2">
<h2>Run</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/filter_swords_batch.py</code></pre>
<aside class="notes">
<ul>
<li>This isn’t yet streaming, we were just cleaning up particulary explicitly specifying schema</li>
</ul>
</aside>
</section>
<section id="turn-that-into-a-stream" class="level2">
<h2>Turn that into a stream</h2>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb36-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb36-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb36-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb36-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb36-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</a>
<a class="sourceLine" id="cb36-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf, from_json</a>
<a class="sourceLine" id="cb36-7" data-line-number="7"><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField, StringType</a>
<a class="sourceLine" id="cb36-8" data-line-number="8"></a>
<a class="sourceLine" id="cb36-9" data-line-number="9"></a>
<a class="sourceLine" id="cb36-10" data-line-number="10"><span class="kw">def</span> purchase_sword_event_schema():</a>
<a class="sourceLine" id="cb36-11" data-line-number="11">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb36-12" data-line-number="12"><span class="co">    root</span></a>
<a class="sourceLine" id="cb36-13" data-line-number="13"><span class="co">    |-- Accept: string (nullable = true)</span></a>
<a class="sourceLine" id="cb36-14" data-line-number="14"><span class="co">    |-- Host: string (nullable = true)</span></a>
<a class="sourceLine" id="cb36-15" data-line-number="15"><span class="co">    |-- User-Agent: string (nullable = true)</span></a>
<a class="sourceLine" id="cb36-16" data-line-number="16"><span class="co">    |-- event_type: string (nullable = true)</span></a>
<a class="sourceLine" id="cb36-17" data-line-number="17"><span class="co">    |-- timestamp: string (nullable = true)</span></a>
<a class="sourceLine" id="cb36-18" data-line-number="18"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb36-19" data-line-number="19">    <span class="cf">return</span> StructType([</a>
<a class="sourceLine" id="cb36-20" data-line-number="20">        StructField(<span class="st">&quot;Accept&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb36-21" data-line-number="21">        StructField(<span class="st">&quot;Host&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb36-22" data-line-number="22">        StructField(<span class="st">&quot;User-Agent&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb36-23" data-line-number="23">        StructField(<span class="st">&quot;event_type&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb36-24" data-line-number="24">    ])</a>
<a class="sourceLine" id="cb36-25" data-line-number="25"></a>
<a class="sourceLine" id="cb36-26" data-line-number="26"></a>
<a class="sourceLine" id="cb36-27" data-line-number="27"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb36-28" data-line-number="28"><span class="kw">def</span> is_sword_purchase(event_as_json):</a>
<a class="sourceLine" id="cb36-29" data-line-number="29">    <span class="co">&quot;&quot;&quot;udf for filtering events</span></a>
<a class="sourceLine" id="cb36-30" data-line-number="30"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb36-31" data-line-number="31">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb36-32" data-line-number="32">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb36-33" data-line-number="33">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb36-34" data-line-number="34">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb36-35" data-line-number="35"></a>
<a class="sourceLine" id="cb36-36" data-line-number="36"></a>
<a class="sourceLine" id="cb36-37" data-line-number="37"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb36-38" data-line-number="38">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb36-39" data-line-number="39"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb36-40" data-line-number="40">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb36-41" data-line-number="41">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb36-42" data-line-number="42">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb36-43" data-line-number="43">        .getOrCreate()</a>
<a class="sourceLine" id="cb36-44" data-line-number="44"></a>
<a class="sourceLine" id="cb36-45" data-line-number="45">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb36-46" data-line-number="46">        .readStream <span class="op">\</span></a>
<a class="sourceLine" id="cb36-47" data-line-number="47">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb36-48" data-line-number="48">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb36-49" data-line-number="49">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb36-50" data-line-number="50">        .load()</a>
<a class="sourceLine" id="cb36-51" data-line-number="51"></a>
<a class="sourceLine" id="cb36-52" data-line-number="52">    sword_purchases <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb36-53" data-line-number="53">        .<span class="bu">filter</span>(is_sword_purchase(raw_events.value.cast(<span class="st">&#39;string&#39;</span>))) <span class="op">\</span></a>
<a class="sourceLine" id="cb36-54" data-line-number="54">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw_event&#39;</span>),</a>
<a class="sourceLine" id="cb36-55" data-line-number="55">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb36-56" data-line-number="56">                from_json(raw_events.value.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb36-57" data-line-number="57">                          purchase_sword_event_schema()).alias(<span class="st">&#39;json&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb36-58" data-line-number="58">        .select(<span class="st">&#39;raw_event&#39;</span>, <span class="st">&#39;timestamp&#39;</span>, <span class="st">&#39;json.*&#39;</span>)</a>
<a class="sourceLine" id="cb36-59" data-line-number="59"></a>
<a class="sourceLine" id="cb36-60" data-line-number="60">    query <span class="op">=</span> sword_purchases <span class="op">\</span></a>
<a class="sourceLine" id="cb36-61" data-line-number="61">        .writeStream <span class="op">\</span></a>
<a class="sourceLine" id="cb36-62" data-line-number="62">        .<span class="bu">format</span>(<span class="st">&quot;console&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb36-63" data-line-number="63">        .start()</a>
<a class="sourceLine" id="cb36-64" data-line-number="64"></a>
<a class="sourceLine" id="cb36-65" data-line-number="65">    query.awaitTermination()</a>
<a class="sourceLine" id="cb36-66" data-line-number="66"></a>
<a class="sourceLine" id="cb36-67" data-line-number="67"></a>
<a class="sourceLine" id="cb36-68" data-line-number="68"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb36-69" data-line-number="69">    main()</a></code></pre></div>
<aside class="notes">
<ul>
<li>What’s different: <code>raw_events = spark.readStream ...</code> instead of just read</li>
<li>In batch one, we tell it offsets, and tell it to read</li>
<li>In streaming, no offsets</li>
<li><code>query =</code> section &amp; <code>query.awaitTermination</code> sections are differences</li>
</ul>
</aside>
</section>
<section id="run-it" class="level2">
<h2>Run it</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/filter_swords_stream.py</code></pre>
<aside class="notes">
<ul>
<li>run in stream,</li>
<li>kick some events</li>
<li>feed it to automaically generate events, can see that grow in hdfs</li>
</ul>
</aside>
</section>
<section id="kick-some-more-events" class="level2">
<h2>Kick some more events</h2>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user1.comcast.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids \
  ab \
    -n 10 \
    -H &quot;Host: user2.att.com&quot; \
    http://localhost:5000/purchase_a_sword</code></pre>
<p>::: notes</p>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/</code></pre>
<pre><code>docker-compose exec mids ab -n 10 -H &quot;Host: user2.att.com&quot; http://localhost:5000/purchase_a_sword</code></pre>
</section>
<section id="write-from-a-stream" class="level2">
<h2>Write from a stream</h2>
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="co">#!/usr/bin/env python</span></a>
<a class="sourceLine" id="cb46-2" data-line-number="2"><span class="co">&quot;&quot;&quot;Extract events from kafka and write them to hdfs</span></a>
<a class="sourceLine" id="cb46-3" data-line-number="3"><span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb46-4" data-line-number="4"><span class="im">import</span> json</a>
<a class="sourceLine" id="cb46-5" data-line-number="5"><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</a>
<a class="sourceLine" id="cb46-6" data-line-number="6"><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf, from_json</a>
<a class="sourceLine" id="cb46-7" data-line-number="7"><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField, StringType</a>
<a class="sourceLine" id="cb46-8" data-line-number="8"></a>
<a class="sourceLine" id="cb46-9" data-line-number="9"></a>
<a class="sourceLine" id="cb46-10" data-line-number="10"><span class="kw">def</span> purchase_sword_event_schema():</a>
<a class="sourceLine" id="cb46-11" data-line-number="11">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb46-12" data-line-number="12"><span class="co">    root</span></a>
<a class="sourceLine" id="cb46-13" data-line-number="13"><span class="co">    |-- Accept: string (nullable = true)</span></a>
<a class="sourceLine" id="cb46-14" data-line-number="14"><span class="co">    |-- Host: string (nullable = true)</span></a>
<a class="sourceLine" id="cb46-15" data-line-number="15"><span class="co">    |-- User-Agent: string (nullable = true)</span></a>
<a class="sourceLine" id="cb46-16" data-line-number="16"><span class="co">    |-- event_type: string (nullable = true)</span></a>
<a class="sourceLine" id="cb46-17" data-line-number="17"><span class="co">    |-- timestamp: string (nullable = true)</span></a>
<a class="sourceLine" id="cb46-18" data-line-number="18"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb46-19" data-line-number="19">    <span class="cf">return</span> StructType([</a>
<a class="sourceLine" id="cb46-20" data-line-number="20">        StructField(<span class="st">&quot;Accept&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb46-21" data-line-number="21">        StructField(<span class="st">&quot;Host&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb46-22" data-line-number="22">        StructField(<span class="st">&quot;User-Agent&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb46-23" data-line-number="23">        StructField(<span class="st">&quot;event_type&quot;</span>, StringType(), <span class="va">True</span>),</a>
<a class="sourceLine" id="cb46-24" data-line-number="24">    ])</a>
<a class="sourceLine" id="cb46-25" data-line-number="25"></a>
<a class="sourceLine" id="cb46-26" data-line-number="26"></a>
<a class="sourceLine" id="cb46-27" data-line-number="27"><span class="at">@udf</span>(<span class="st">&#39;boolean&#39;</span>)</a>
<a class="sourceLine" id="cb46-28" data-line-number="28"><span class="kw">def</span> is_sword_purchase(event_as_json):</a>
<a class="sourceLine" id="cb46-29" data-line-number="29">    <span class="co">&quot;&quot;&quot;udf for filtering events</span></a>
<a class="sourceLine" id="cb46-30" data-line-number="30"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb46-31" data-line-number="31">    event <span class="op">=</span> json.loads(event_as_json)</a>
<a class="sourceLine" id="cb46-32" data-line-number="32">    <span class="cf">if</span> event[<span class="st">&#39;event_type&#39;</span>] <span class="op">==</span> <span class="st">&#39;purchase_sword&#39;</span>:</a>
<a class="sourceLine" id="cb46-33" data-line-number="33">        <span class="cf">return</span> <span class="va">True</span></a>
<a class="sourceLine" id="cb46-34" data-line-number="34">    <span class="cf">return</span> <span class="va">False</span></a>
<a class="sourceLine" id="cb46-35" data-line-number="35"></a>
<a class="sourceLine" id="cb46-36" data-line-number="36"></a>
<a class="sourceLine" id="cb46-37" data-line-number="37"><span class="kw">def</span> main():</a>
<a class="sourceLine" id="cb46-38" data-line-number="38">    <span class="co">&quot;&quot;&quot;main</span></a>
<a class="sourceLine" id="cb46-39" data-line-number="39"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb46-40" data-line-number="40">    spark <span class="op">=</span> SparkSession <span class="op">\</span></a>
<a class="sourceLine" id="cb46-41" data-line-number="41">        .builder <span class="op">\</span></a>
<a class="sourceLine" id="cb46-42" data-line-number="42">        .appName(<span class="st">&quot;ExtractEventsJob&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-43" data-line-number="43">        .getOrCreate()</a>
<a class="sourceLine" id="cb46-44" data-line-number="44"></a>
<a class="sourceLine" id="cb46-45" data-line-number="45">    raw_events <span class="op">=</span> spark <span class="op">\</span></a>
<a class="sourceLine" id="cb46-46" data-line-number="46">        .readStream <span class="op">\</span></a>
<a class="sourceLine" id="cb46-47" data-line-number="47">        .<span class="bu">format</span>(<span class="st">&quot;kafka&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-48" data-line-number="48">        .option(<span class="st">&quot;kafka.bootstrap.servers&quot;</span>, <span class="st">&quot;kafka:29092&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-49" data-line-number="49">        .option(<span class="st">&quot;subscribe&quot;</span>, <span class="st">&quot;events&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-50" data-line-number="50">        .load()</a>
<a class="sourceLine" id="cb46-51" data-line-number="51"></a>
<a class="sourceLine" id="cb46-52" data-line-number="52">    sword_purchases <span class="op">=</span> raw_events <span class="op">\</span></a>
<a class="sourceLine" id="cb46-53" data-line-number="53">        .<span class="bu">filter</span>(is_sword_purchase(raw_events.value.cast(<span class="st">&#39;string&#39;</span>))) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-54" data-line-number="54">        .select(raw_events.value.cast(<span class="st">&#39;string&#39;</span>).alias(<span class="st">&#39;raw_event&#39;</span>),</a>
<a class="sourceLine" id="cb46-55" data-line-number="55">                raw_events.timestamp.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb46-56" data-line-number="56">                from_json(raw_events.value.cast(<span class="st">&#39;string&#39;</span>),</a>
<a class="sourceLine" id="cb46-57" data-line-number="57">                          purchase_sword_event_schema()).alias(<span class="st">&#39;json&#39;</span>)) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-58" data-line-number="58">        .select(<span class="st">&#39;raw_event&#39;</span>, <span class="st">&#39;timestamp&#39;</span>, <span class="st">&#39;json.*&#39;</span>)</a>
<a class="sourceLine" id="cb46-59" data-line-number="59"></a>
<a class="sourceLine" id="cb46-60" data-line-number="60">    sink <span class="op">=</span> sword_purchases <span class="op">\</span></a>
<a class="sourceLine" id="cb46-61" data-line-number="61">        .writeStream <span class="op">\</span></a>
<a class="sourceLine" id="cb46-62" data-line-number="62">        .<span class="bu">format</span>(<span class="st">&quot;parquet&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-63" data-line-number="63">        .option(<span class="st">&quot;checkpointLocation&quot;</span>, <span class="st">&quot;/tmp/checkpoints_for_sword_purchases&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-64" data-line-number="64">        .option(<span class="st">&quot;path&quot;</span>, <span class="st">&quot;/tmp/sword_purchases&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-65" data-line-number="65">        .trigger(processingTime<span class="op">=</span><span class="st">&quot;10 seconds&quot;</span>) <span class="op">\</span></a>
<a class="sourceLine" id="cb46-66" data-line-number="66">        .start()</a>
<a class="sourceLine" id="cb46-67" data-line-number="67"></a>
<a class="sourceLine" id="cb46-68" data-line-number="68">    sink.awaitTermination()</a>
<a class="sourceLine" id="cb46-69" data-line-number="69"></a>
<a class="sourceLine" id="cb46-70" data-line-number="70"></a>
<a class="sourceLine" id="cb46-71" data-line-number="71"><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</a>
<a class="sourceLine" id="cb46-72" data-line-number="72">    main()</a></code></pre></div>
</section>
<section id="run-it-1" class="level2">
<h2>Run it</h2>
<pre><code>docker-compose exec spark spark-submit /w205/full-stack2/write_swords_stream.py</code></pre>
</section>
<section id="feed-it" class="level2">
<h2>Feed it</h2>
<pre><code>while true; do
  docker-compose exec mids \
    ab -n 10 -H &quot;Host: user1.comcast.com&quot; \
      http://localhost:5000/purchase_a_sword
  sleep 10
done</code></pre>
<aside class="notes">
<pre><code>while true; do docker-compose exec mids ab -n 10 -H &quot;Host: user1.comcast.com&quot; http://localhost:5000/purchase_a_sword; sleep 10; done</code></pre>
</aside>
</section>
<section id="check-what-it-wrote-to-hadoop" class="level2">
<h2>Check what it wrote to Hadoop</h2>
<pre><code>docker-compose exec cloudera hadoop fs -ls /tmp/sword_purchases</code></pre>
<aside class="notes">
<ul>
<li>Hadoop is unhappy with lots of small (e.g., like this 2.7K) files,</li>
<li>but the size of the files that we’re writing have to do with the processing time</li>
<li>been writing batch jobs using structured streaming type syntax</li>
<li>show different ways to partition with day or hour etc</li>
</ul>
</aside>
</section>
</section>
<section id="section-10" class="slide level1">
<h1></h1>
<section id="down" class="level2">
<h2>down</h2>
<pre><code>docker-compose down</code></pre>
<aside class="notes">

</aside>
</section>
</section>
<section id="section-11" class="slide level1">
<h1></h1>
<section id="summary" class="level2">
<h2>summary</h2>
</section>
<section id="section-12" class="level2" data-background="images/pipeline-steel-thread-for-mobile-app.svg">
<h2></h2>
</section>
</section>
<section id="section-13" class="slide level1">
<h1></h1>
<p><img class="logo" src="images/berkeley-school-of-information-logo.png"/></p>
</section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Transition style
        transition: 'linear', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
